\documentclass{article}

\usepackage{nips_2018_author_response}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
% \usepackage{microtype}      % microtypography
%\usepackage{ stmaryrd }

\usepackage{lipsum}
\usepackage{xcolor}
\newcommand{\rev}[1]{{\color{red} #1}}
% \newcommand{\rev}[1]{}
\newcommand{\umut}[1]{{\color{blue} #1}}
\newcommand{\alain}[1]{{\color{cyan} #1}}
\newcommand{\antoine}[1]{{\color{orange} #1}}
\newcommand{\ubul}[1]{{\large \color{red} \textcircled{\small #1}}}
\newcommand{\uunder}[1]{\underline{\smash{#1}}}


\begin{document}
We thank the reviewers for their comments and feedback. We appreciate that our approach was found original, technically correct, and clearly presented. We believe we addressed all the criticized points and we hope that the reviewers will reconsider their final marks.
We start by addressing the common concerns:
\vspace{1.5pt}\\
% \textbf{General Responses:}
% \textbf{\underline{The term `MCMC':}} We suspect that the term `MCMC' in our title might have raised confusion. We see MCMC as a family of methods for \emph{generating samples from a distribution by simulating a Markov chain}. From this respect, our approach indeed has the same goal: generating samples from the data distribution by simulating a Markov chain (Eqn 7,9). On the other hand, \emph{SWF is definitely \textbf{not} a Bayesian posterior sampling algorithm}. We understand the reviewers' concern and propose replacing the term `MCMC' in the title with `Diffusions'. \vspace{1.5pt}\\
%
% this is the reason why we chose to use the term MCMC.
%
\textbf{\uunder{Contributions \& Experiments:}} We highlight that, to our knowledge, SWF is the first nonparametric IGM algorithm with explicit theoretical guarantees. In this respect, our approach is \emph{substantially} new and might introduce a new branch to IGM.
% Besides, the random projections bring an interesting feature which might have important implications in terms of privacy.
Since many concepts and proofs are introduced in this paper, it has a resolutely theoretical flavour, which we believe is its main strength.
The proposed method is validated by `proof-of-concept' experiments, whose objective is \emph{not} to achieve state-of-the-art results. This part is the topic of ongoing research and is not claimed in the paper. This said, assessing the validity of IGM algorithms \emph{is generally done by visualizing the generated samples, as is done in our paper.} To enable comparison with other algorithms, we will include their visual results in the supp.\ \vspace{2pt} \\
%
% \umut{As a general response -- Experiments}
%
\textbf{\color{red} \uunder{Rev. 1: }}
%
We thank R1 for the detailed positive review
%and the positive comments on the originality and clarity,
and the very relevant suggestions for minor modifications.\\ % of our submission.
%
% \rev{I think the experiments section has room for improvement. For instance, one advantage of the SWF method is computational efficiency. How would this idea then scale up to higher resolution images or a more complex data set?}
%
\textbf{\uunder{Experiments:}} SWF is not so much dependent on the actual dimension of the data but its \textit{complexity}: generating MNIST seems much easier than generating CelebA images of the same dimension. We suspect a dependency between $N_\theta$ and the structure of the data, as in the theory of compressed sampling. We will have a discussion on this matter. \\
\textbf{\uunder{Manipulation:}} This topic was overlooked due to space limitations. One possible way is to interpolate two particles coming from $\mu$ in the beginning of the algorithm and observe the outputs of the algorithm for the interpolated particles. We have conducted new experiments now and obtained interesting outcomes, which we will present in the supp.\ doc. \\
%
% The proposed method is not so much dependent on the actual dimension of the data and is rather dependent on its \textit{complexity}. Indeed, generating (up-sampled) MNIST digits does behave very well, whereas CelebA images of the same dimension are still a challenge. We suspect that there is a relation between $N_\theta$ and the structure of the data, as in the theory of compressed sampling. We will have a discussion on this matter. % These considerations however require further investigation and were left out of the present paper.
%
% \rev{Is there a way to assess the validity or quality of the implicit generative model?}
%
% \textbf{\underline{Validity:}} Although an established strategy is to simply display generated samples for visual inspection, we agree that a more objective evaluation would be desirable. In this respect, several scores such as Inception may be mentioned. It is also remarkable that the SW2 distance itself is considered for this purpose in some very recent studies. In the revised version, we plan on displaying the evolution of such an established score along iterations.
%
% \rev{Is there a way to manipulate the model to alter generated samples (e.g. along a latent dimension)?}
%
% \umut{We in fact didn't try this. Antoine, let's talk about this to see if we can put a figure on this.}
% \antoine{An idea to manipulate samples could be to apply some reversed SWF, so as to go from the data distribution $\nu$ to the proposal distribution $\mu$, apply some transformation, and apply SWF again to go back to the signal domain. Another idea to alter samples could be to do the learning of a joint distribution between the data and some latent features. Controlling such features during SWF could allow altering the generated samples. We think such ideas could be very interesting for future work.}
%
% \rev{- The result of the algorithm is a set of particles — synthesized data? I may be missing something — Is there a way to recover the generative process so you can generate new particles? If you already have samples from the empirical distributions, what does having simulations afford?}
%
\textbf{\uunder{Generating new particles:}} It is totally possible to generate new particles once the generative process has been applied once. This is simply done by first remembering the CDF and QF of the particles the first time they went through the flow, then using them for any other new particle. This is what we meant by "estimation" and "prediction" stages in Fig 1. The revised version will make this clearer. \\
%
%
% We fully agree that our original submission was not clear enough on this point. Yes, it is totally possible to generate new particles once the generative process has been applied once. This is simply done by remembering the cumulative function from the particles the first time they went through the flow, to be used for any other new particle. This is what we meant by "estimation" and "prediction" stages. The revised version will make this clearer.
%
%
% \rev{- In the experiments you say you observe N=3000 particles are sufficient —- sufficient for what? To compare certain estimated quantities?}
%
\textbf{\uunder{Num. of particles:}} Yes, $N=3000$ gives us sufficiently accurate quantiles estimates. We will clarify this issue. \\
%
% \antoine{In our experiments, we did not notice any difference between the observed quantile functions whenever $N$ was large enough.}
% \umut{Antoine?}
%
% \rev{- What was the qualitative effect of the regularization parameter on the real data set? Did you notice the samples converging to fainter or fuzzier images?}
\textbf{\uunder{Effect of $\lambda$:}} As the reviewer mentions, larger $\lambda$ yields fuzzier images. We will illustrate this in the supp.\ doc. \\
%
% \antoine{Honestly, I don't think there was too much influence of this parameter, except than theoretical validity....}
% \umut{Yes? Antoine?}
%
% \rev{- Within this framework, how would you assess overfitting? Could it be possible that the flow ends up just reproducing examples from the training data?}
\textbf{\uunder{Overfitting:}} This is a very good question. We did not observe such a reproduction; we will illustrate this claim by plotting the closest samples from the training data beside a set of generated images. \vspace{2pt} \\
% \umut{Very good question, I don't know.}
% \antoine{We did not observe such a reproduction. Intuitively, each sample of the dataset is only observed through a limited number of projections, which is insufficient to reconstruct it again. Hence, it shouldn't be easy for the algorithm to reproduce this sample. However, we now illustrate this claim by plotting the closest samples from the training data beside a set of generated images.}
%
\textbf{\color{red} \underline{Rev. 2:}}
%
We must admit that we found some comments and the rejection conclusion very harsh. We would like to clarify that our proposed algorithm is \textbf{not} a gradient-based MCMC algorithm, but a nonparametric IGM algorithm only using ideas from Langevin MCMC. We felt the title was not clear enough in this respect. Please refer to the response \ubul{1} below and the initial notes for more clarifications.
%
Then, we agree that the paper is resolutely technical and that our notations might sometimes feel new, bringing previously disconnected fields together:  IGM, gradient flows and diffusions. However, care was taken to have them consistent and rigorous. The two other reviewers explicitly appreciated our effort to carefully organize and write this paper, notwithstanding its technicalness. On the other hand, we do not understand which proofs the reviewer is referring to, since all the proofs are already provided in the supplementary document. Finally, ESS would not be an appropriate metric for measuring the performance since we are not in a classical MCMC setting. We would very much appreciate the reviewer to reconsider our submission.\vspace{2pt} \\
% \rev{The paper claims to be proposing a novel gradient-based MCMC algorithm but its main idea seems to be driven by the SGLD algorithm.}
% \umut{Wrong.}
% \rev{The paper also proposes to use the SW2 distance with some regularisation term as the objective function, but I fail to see how this is a novel contribution to their proposed MCMC method.}
% \umut{Good for you.}
% \rev{I find the paper to be poorly written and quite hard to follow. It is filled with math proofs that can be moved to the appendix section.}
% \umut{WTF? We should mention that it's technical paper.}
% \rev{Also, the experiment section is very weak. They only provided visual samples on toy datasets and failed to provide qualitative measurements on their samples such as using ESS.}
%
% \umut{ESS is meaningless. We should refer to the initial explanation.}
%
\textbf{\color{red} \underline{Rev. 3:}}
%
We thank the reviewer for the very detailed investigation and constructive comments. % We believe we have addressed bla bla. We hope the reviewer can increase the grade etc.
%
% \rev{1. The title of the paper is "Sliced-Wasserstein Flows: Nonparametric Generative Modeling via Optimal Transport and MCMC". This is a bit misleading. I do not see that the proposed algorithm has an MCMC aspect on it. The authors state that "gradient flow and is reminiscent of stochastic gradient Markov Chain Monte Carlo (MCMC) methods". But it does not justify saying that this is a generative modeling algorithm via MCMC.}
%
\ubul{1} We see MCMC as a family of methods for \emph{generating samples from a distribution by simulating a Markov chain}. In this sense, SWF indeed has the same goal: generating samples from $\nu$ by simulating the Markov chain in Eqn 7. On the other hand, \emph{SWF is definitely \textbf{not} a Bayesian posterior sampling algorithm}. We understand the concern and propose replacing the term `MCMC' in the title with `Diffusions'.
%
% \rev{2. Furthermore, it is not clear to me how the proposed algorithm is nonparametric.}
%
\ubul{2} SWF is nonparametric in the sense that the transport map it generates between $\mu$ and $\nu$ does not belong to some family of functions, like a deep network.
% At each iteration, the map is augmented with the application of another function, yielding a truly non-parametric approach.
We will clarify this in the revision.
%
% \rev{3. In Section 1, $T_t$ is proposed as a transport map at time t. What is the range of t? I suspect it is $(0, \infty)$ only from Section 3.}
%
\ubul{3} Yes, indeed $t \in [0, \infty)$. We will clarify this issue.
%
% \rev{4. Again in Section 1, the authors state that "One would hope for $\mu_t = T_t \#\mu$ to converge to the minimum of the functional optimization problem." Has there been any theoretical studies on this? If so, any citations?}
%
\ubul{4} We will cite the last sections of [21]. % and clarify this comment.
%
% \alain{4. Unfortunately, there is only a few results regarding the convergence of gradient flows to global minimizers of the functional of interest, expect in the case where this functional is geodesically convex in the Wasserstein space $(\mathcal{P}_2,W_2)$. }
%
% \rev{5. In the end of Section 1, it says that "we are able to develop a practical algorithm that provides approximate solutions to the gradient flow and is reminiscent of stochastic gradient Markov Chain Monte Carlo (MCMC) methods." I don't see how the proposed algorithm is reminiscent of stochastic gradient Markov Chain Monte Carlo (MCMC) methods.}
%
\ubul{5} This question is partially answered in lines 259-263. Stochastic gradient MCMC (SG-MCMC) methods are based on simulating SDEs. The most well-known SG-MCMC approach being SGLD, is obtained by discretizing $d X_t = - \nabla U(X_t) dt + \sqrt{2} dW_t$ which resembles the SDE in Eqn 7. Here, $U$ neither depends on $t$ nor $\mu_t$. In this sense, SWF is similar to SGLD: we also discretize a (much more complicated) SDE for generating samples from a target distribution. We will clarify this issue.
% by improving the paragraph in lines 259-263.
%
% \rev{6. In Section 2, the authors write that "The optimal map T is also known as the increasing arrangement, which maps each quantile of $\mu$ to the same quantile of $\nu$, e.g. minimum to minimum, median to median, maximum to maximum." Is there a reference for this?}
%
\ubul{6} We will cite the corresponding chapter of [7]. % and clarify this comment.
%
% \antoine{We now refer to the book by C. Villani for a proof of this fact.}
%
% \rev{7. At the end of Section 2, the authors write that "Therefore, one can easily approximate (4) by using a simple Monte Carlo scheme that draws uniform random samples from $S^{d-1}$ and replace the integral in (4) with a finite-sample average." I think that the problem with this simple Monte Carlo method is that when d is large, the approximation will be very poor. This is not made clear in the paper and I think that it is an important issue that should be discussed further in the paper.}
%
% \umut{Antoine, what happens if we use a very small number of projections? It gives shitty results or not?}
% \antoine{See the answer we gave to Rev. 1 for an answer to this very relevant question.}
\ubul{7} Please see the `\textbf{Experiments}' response that we provided for Rev.\ 1.
% \rev{8. It appears to me that the proposed approach requires that $\mu$ and $\nu$ have the same support/dimension d. This may seriously limit its application as it cannot be used in purposes like dimension reduction.}
%
% \umut{True. Don't we discuss this in the conclusion?}
%
\ubul{8} In fact, the theory allows us to use a lower dimensional $\mu$ by using
% the only requirement on $\mu$ is that it has finite second-order moments and is non-atomic.
a very simple trick: if $\mu$ is $d' \ll d$ dimensional, we can generate a random sample from $\mu$ and multiply it by a random full-rank matrix of size $d' \times d$, and use this output in the algorithm. We did not notice any difference in performance between using this trick for small input dimensions and directly taking $\mu$ as high dimensional, hence we omitted this feature. We will mention this topic in the paper.
%
% \rev{9. I like the fact that there are detailed discussions about related work in the paper with the page limit. However, there is no comparison with the state-of-the-art algorithms in this domain at all in the experiment section. The authors wrote that "The whole experiment on the FashionMNIST requires around 1 hour of computational time on the CPU of a standard laptop computer, to be compared with the significant resource requirements of the current IGM methods." But what are these compared IGM methods and what is the quantitative performance comparison with these methods besides the computational/resource requirements?}
%
%\antoine{We were tacitly referring to parametric IGM methods such as GANs. The fact is that such methods have been witnessing a tremendous popularity in the recent years and the quality of generated samples is good. ***In terms of qualitative metrics, can we skip the comparison?***}
% \umut{We should explicitly mention those methods. We should mention that it's difficult to compare these approaches.}
\ubul{9} We were tacitly referring to parametric IGM methods such as the recent GANs and VAEs, we will clarify this issue. Please see our initial comment about comparison with these methods.
% \rev{10. Theorem 3 shows that when h is small enough, there is a non-asymptotic error guarantee. The first experiment chooses h = 1. Is this considered a big value? The value of h for the second experiment is not provided.}
%
% \antoine{The parameter $h$ may be thought of as a learning rate. In our experiments, we took $h=1$ everywhere. Still, experiments with smaller $h$ may lead to better results, even if performance is much slower? Should we do this? Do we have time?...}
% \umut{Oops. Antoine, Alain, what do we say?}
%
% \alain{we could say that ``due to space constraints, we did not give a full numerical study of the effect of the step size on generated models''}
\ubul{10} Even though the guarantees are for small $h$, the theory does not imply that larger $h$ would not perform well. In all the experiments we used $h=1$ and observed that we obtain similar performance within a smaller amount of time.
% \rev{11. What is $N_\theta$ in Section 4, and what is $L^1$ in Equation (3) in Section 2?}
%
\ubul{11} $N_\theta$ denotes the number of projections $\theta_{k,n}$ (i.e.\ $n \in \llbracket 1, N_\theta \rrbracket$) and it is implicitly defined in line 206. $L^1(\mu)$ denotes the absolutely integrable functions under $\mu$. We will clarify these definitions.
%
% \rev{12. Typos: Ref [1]: Monte carlo -> Monte Carlo; Ref [4]: bayes -> Bayes; Ref [14]: Gan and vae: GAN and VAE; etc.}
%
\ubul{12} We have corrected all the typos, thank you for pointing out.


\end{document}
