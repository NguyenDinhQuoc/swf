%!TEX root = ./nips_2018_sketchmcmc.tex

\section{Regularized Sliced-Wasserstein Flows for Generative Modeling}

% \begin{itemize}
% \item Start from the flow given in \cite{bonnotte2013unidimensional} and discuss the limitations 
% \begin{itemize}
% \item No convergence guarantee
% \item Over-fitting risk when the target is a collections of Dirac masses
% \end{itemize}
% \item Motivation for the entropy-regularization (discuss the differences with the Sinkhorn distances \cite{genevay2018learning})
% \item Development of the new gradient flow -- first theoretical result
% \item Establish the distance between the stationary measures of the two gradient flows (second theoretical result)
% \item View the new flow as a non-linear Fokker-Planck equation -- establish the connection with the appropriate SDE
% \item Develop the numerical scheme 
% \item Analyze the TV distance between the measure at iteration $k$ and the invariant measure
% \item We don't need to see the data, we just need the projections. In addition to its computational implications, this can be crucial for privacy preserving applications
% \end{itemize}


Bonnotte \cite{bonnotte2013unidimensional} considers the IDT algorithm \cite{pitie2005n} and develops a continuity equation, given as follows:
\begin{align}
\partial_t \rho_t - \nabla \cdot (\rho_t v_t) = 0,
\end{align}
where $\rho_t$ is the density of $\mu_t$ and
\begin{align}
v_t(x) \triangleq \int_{\mathbb{S}^{d-1}} \psi'_{t,\theta}(\langle \theta, x \rangle) \theta \> d\theta. \label{eqn:idt_v}
\end{align}
Here, $\psi_{t,\theta}$ denotes the Kantorovich potential between $\theta^*_{\#}\mu_t$ and $\theta^*_{\#}\nu$. In fact, one can show that, this is nothing but a gradient flow in the Wasserstein spaces, given as follows:
\begin{align}
\partial_t \rho = - \nabla_{\W} \F(\rho) \label{eqn:gradflow}
\end{align}
where $\nabla_{\W}$ denotes a notion of gradient in the $\W$ metric and the functional $\F$ is chosen as the squared sliced-Wasserstein distance between $\mu$ and $\nu$:
\begin{align}
\F(\rho) \triangleq \frac1{2} \SW^2(\rho, \pi)
\end{align}
where $\pi$ denotes the density of $\nu$. Here we abused the notation by defining $\SW$ on the densities instead of the measures; we implicitly assume that both measures $\mu$ and $\nu$ are dominated by the Lebesgue measure. This gradient flow basically constructs a path $(\rho_t)_{t\geq 0}$ that minimizes $\F$ as $t$ increases. In other words, the goal in construction such a flow is to solve the following problem:
\begin{align}
\rho^\star = \argmin_\rho \F(\rho).
\end{align}
Since we obviously have $\rho^\star = \pi$, this gradient flow will start from $\rho_0$ and bring it closer to $\pi$ as $t$ evolves.

% By following \cite{santambrogio2017euclidean}, the gradient given in \eqref{eqn:gradflow} can be written as follows:
% \begin{align}
% \nabla_{\W} \F(\rho) = -\nabla \cdot \Bigl( \rho \nabla \bigl( \frac{\delta \F}{\delta \rho}(\rho) \bigr) \Bigr), \label{eqn:gradw2}
% \end{align}
% where $\frac{\delta \F}{\delta \rho}(\rho)$ denotes the first variation of $\F$.

By this definition, $\mu_t$ should directly go to $\nu$. However, in practical settings, we will have finitely many samples from $\mu_0$ and $\nu$, therefore this scheme will somehow `overfit' to the data distribution. Therefore what we propose is to somehow `regularize' the gradient flow by introducing an entropy term to the minimization process. In particular, we modify the gradient flow given in \eqref{eqn:gradflow} as follows:
\begin{align}
\partial_t \rho = - \nabla_{\W} \F_\lambda(\rho),
\end{align}
where
\begin{align}
\F_\lambda(\rho) \triangleq \F(\rho) + \lambda \He(\rho).
\end{align}
Here, $\He(\rho) \triangleq \int (h \circ \rho) (x) dx $ denotes the negative entropy of $\rho$ with $h(t) = t \log t$. This regularization somewhat corresponds to assuming a Gaussian prior on the density $\rho$: when $\lambda$ goes to infinity, the optimal $\rho$ that minimizes $\F_\lambda$ will be a Gaussian density since the Gaussian densities have the maximum entropy.


This time the optimization problem is modified:
\begin{align}
\min_\rho \F_\lambda(\rho),
\end{align}
in which $\pi$ is no longer an optimizer. The idea in this new gradient flow formulation is to take $\rho_t$ as close as possible to $\pi$, while trying to keep its entropy at a certain level, so that it would be expressive for generative modeling purposes.

% We can now construct the modified gradient flow as follows:
% \begin{align}
% \partial_t \rho &= - \nabla_{\W} \F_\lambda(\rho) \\
% &=  \nabla \cdot (\rho \> v_t) + \lambda \Delta \rho. \label{eqn:gradflow_reg}
% \end{align}

% Here, we present our first theoretical result. 
% \begin{thm}
% The gradient flow is a valid gradient flow. \umut{Szymon.}
% \end{thm}

% We let $\mathcal{F}_{\lambda}(\mu) = \frac{1}{2} SW_2^2(\mu, \nu) + \lambda H(\mu)$ for a chosen reference measure $\nu$.

% \begin{lemma}
% Let $\nu$ be a probability measure on $\cB(0,1)$ with a strictly positive smooth density. Fix a time step $h > 0$, regularization constant $\lambda > 0$ and a radius $r > \sqrt{d}$. For a probability measure $\mu_0$ on $B(0, r)$ with density $\rho_0 \in L^{\infty}$, there is a probability measure $\mu$ on $\overline{B}(0,r)$ minimizing:
% \[
% \mathcal{G}(\mu) = \mathcal{F}_{\lambda} (\mu) + \frac{1}{2h} W_2^2(\mu, \mu_0) 
% \]
% Moreover the optimal $\mu$ has a density $\rho$ on $B(0,r)$ and:
% \begin{equation} \label{ineq:inf_norm_bound}
% ||\rho||_{L^{\infty}} \leq (1 + h/\sqrt{d})^d ||\rho_0||_{L^{\infty}}
% \end{equation}
% \end{lemma}

\begin{thm} \label{thm:existance_gmm_scheme}
Let $\nu$ be a probability measure on $\cB(0,1)$ with a strictly positive smooth density. Choose a regularization constant $\lambda > 0$ and radius $r > \sqrt{d}$. Given an absolutely continuous measure $\mu_0 \in \mathcal{P}(\cB(0,r))$ with density $\rho_0 \in L^p$, there is a Lipschitz generalized minimizing movement scheme $(\mu_t)_{t\geq 0}$ in $\mathcal{P}(\cB(0,r))$ starting from $\mu_0$ for the functional:
\[
\mathcal{F}(h, n , \mu_+, \mu_-) = \mathcal{F}_{\lambda}(\mu_+) + \frac{1}{2h}\W(\mu_+, \mu_-)
\]
Morover for time $t > 0$ measure $\mu_t$ has density $\rho_t$ and:
\[
||\rho_t||_{L^p} \leq e^{t\sqrt{d}}/q ||\rho_0||_{L^p}.
\]
\end{thm}


\begin{thm}
Let $\mu_t$ be a generalized minimizing movement scheme given by \ref{thm:existance_gmm_scheme}. We denote by $\rho_t$ the denisty of $\mu_t$. Then $\rho_t$ satisfies the continuity equation:
\begin{align}
\frac{\partial \rho_t}{\partial t} + \text{div}(v_t \rho_t) = \lambda \Delta \rho_t  \quad \quad \quad v_t(x) = - \int_{\Sp^{d-1}} \psi_{t, \theta}'(\langle x , \theta \rangle ) \theta d\theta  \label{eqn:gradflow_reg}
\end{align}
in a weak sense.
\end{thm}


\section{Connection with Stochastic Differential Equations}

We now consider the modified flow given in \eqref{eqn:gradflow_reg}. We can observe that, this equation is a Fokker-Planck-type equation that has a probabilistic counterpart. More precisely, the following stochastic differential equation (SDE):
\begin{align}
d X_t = - v_t(X_t) dt + \sqrt{2 \lambda } d W_t, \label{eqn:sde}
\end{align}
where $W_t$ denotes the standard Brownian motion, is associated with \eqref{eqn:gradflow_reg}, in the sense that the probability measures of the solution process $(X_t)_{t\geq0}$ satisfies the flow \eqref{eqn:gradflow_reg}.  

\begin{assumption}
\label{asmp:sde_ergo}
For all $\lambda >0$, the SDE  \eqref{eqn:sde} has a unique strong solution denoted by $(X_t)_{t\geq 0}$ for any starting point $x \in \R^d$. It defines a non-homogenous Markov semi-group $(P_{s,t})_{t\geq s\geq 0}$ which admits a unique invariant measure denoted by $\nu_\lambda$. 
\end{assumption}



We first provide a bound between the invariant measure $\nu_\lambda$ and $\nu$.

\begin{prop}
\label{prop:dist_statmeas}
Assume that the SDE \eqref{eqn:sde} satisfies \Cref{asmp:sde_ergo}. Denote the probability distribution of $X_t$ at time $t$ by $\mu_t(dx) = \rho_t (x) dx$. Furthermore, consider the following SDE
\begin{align}
d Y_t = - v_t(Y_t) dt + \sqrt{2 \epsilon } d W_t. \label{eqn:sde_eps}
\end{align}
Assume that it satisfies \Cref{asmp:sde_ergo} and denote the probability of $Y_t$ at time $t$ by $\mu^\epsilon_t$ which admits a density $\rho^\epsilon_t$. Further assume that for all $\epsilon,t>0$, there exists $C >0$ that depends on $t$, such that
\begin{align}
\int_{0}^t \int_{\R^d} \frac{\|\nabla \rho^\epsilon_s(x) \|^2}{\rho^\epsilon_s(x)} dx ds <C, \qquad \text{and} \qquad \int_{0}^t \int_{\R^d}  \frac{\|\nabla \rho^\epsilon_s(x)\|}{1+\|x\|} dx ds <\infty.
\end{align}
Then the following bound holds:
\begin{align}
\lim_{\epsilon \rightarrow 0} \| \mu_t - \mu^\epsilon_t \|_{\TV}^2 \leq 2 C \lambda,
\end{align}
where $\|\mu-\nu\|_{\TV}$ denotes the total variation distance between two probability measures $\mu$ and $\nu$, defined as follows: $\|\mu-\nu\|_{\TV}\triangleq \sup_{A \in {\cal B}(\Omega)} |\mu(A) -\nu(A) |$.
\end{prop}

\subsection{Particle system for approximating the SDE and the Euler scheme}

Proposition~\ref{prop:dist_statmeas} shows that if we could simulate \eqref{eqn:sde}, then we could use the sample paths $(X_t)_t$ as
samples drawn from $\nu_\lambda$, which is not very far from $\nu$. However, in practice this is not possible due to two reasons: (i) the drift $v_t$ cannot be computed analytically since it depends on the measure at time $t$, i.e.\ $\mu_t$, (ii) the SDE \eqref{eqn:sde} is a continuous-time process, it needs to be discretized.  

We now focus on the first issue. In order to highlight the fact that the drift in \eqref{eqn:sde} depends on $\mu_t$, within this section we will denote the drift as $v_t(x) \equiv v(x, \mu_t)$. With this notation, it can be clearly observed that the SDE \eqref{eqn:sde} is similar to McKean-Vlasov SDEs \cite{veretennikov2006ergodic,mishura2016existence} whose drift depends on the distribution of $X_t$ as well. By using this connection, we borrow tools from the relevant SDE literature \cite{malrieu03,cgm-08} for developing an approximate simulation method for \eqref{eqn:sde}. 

Our approach is based on defining a \emph{particle system} that serves as an approximation to the original SDE \eqref{eqn:sde}, and is given as follows:
\begin{align}
d X_t^i = - v(X_t^i, \mu_t^{(N)}) dt + \sqrt{2 \lambda } d W_t^i \> , \quad i = 1,\dots, N, \label{eqn:sde_particle}
\end{align}
where $i$ denotes the particle index, $N \in \mathbb{N}_+$ denotes the total number of particles, and $\mu_t^{(N)}$ denotes the law of the particles $\{X_t^j\}_{j=1}^N$. This particle system is particularly interesting, since (i) one typically has $\lim_{N \rightarrow \infty} \mu_t^{(N)}= \mu_t $ and the distance between $\mu_t^{(N)}$ and $\mu_t$ is of order ${\cal O}(1/\sqrt{N})$ for $t$ large enough \cite{malrieu03,cgm-08}, and (ii) each of the particle systems in \eqref{eqn:sde_particle} can be simulated by using an Euler-Maruyama discretization scheme. We note that the existing theoretical results in \cite{veretennikov2006ergodic,mishura2016existence} do not directly apply to our case due to the non-standard form of our drift. However, we conjecture that a similar result holds for our problem as well. Proving such a result is technically very involved and we leave it out of the scope of this study. %We will support this claim with experimental results.

We now consider the approximate Euler-Maruyama discretization for each particle SDE, that is given as follows:
\begin{align}
\bar{X}^i_{k+1} = \bar{X}^i_k - h \hspace{0.5pt} \hat{v}(\bar{X}^i_k, \hat{\mu}_{kh}^N ) + \sqrt{2 \lambda h} Z^i_{k+1},
\end{align}
where $k \in \mathbb{N}_+$ denotes the iteration number, for each particle $i$, $\{Z^i_k\}_{k}$ denotes a series of standard Gaussian random variables in $\R^d$, $h$ denotes the step-size, and $\hat{v}$ is a computationally tractable estimator of $v$. Here, all the initial particles $\{\bar{X}_0^i\}_{i=1}^N$ are drawn from $\mu_0$ in an i.i.d.\ fashion.

We now define a computationally tractable estimator $\hat{v}$ of the drift, given as follows:
\begin{align}
\hat{v}(x,\hat{\mu}) \triangleq - \frac1{N_\theta} \sum_{n=1}^{N_\theta} \psi_{t, \theta_n}'(\langle x , \theta_n \rangle ) \theta_n = \frac1{N_\theta} \sum_{n=1}^{N_\theta} \Bigl[ (F_{\theta_{n\#\hat{\mu}}^*}^{-1} \circ F_{\theta_{n\#\nu}}) (x) - x \Bigr] \theta_n , \label{eqn:approxdrift}
\end{align}
where $\{\theta_n\}_{n=1}^{N_\theta}$ denotes a collection of i.i.d.\ samples that are drawn uniformly on $\Sp^{d-1}$, $F_{\theta_{n\#\hat{\mu}}^*}$ and $F_{\theta_{n\#\nu}^*}$ denote the (one-dimensional) CDFs of $\theta_{n\#\hat{\mu}}^*$ and $\theta_{n\#\nu}^*$, respectively. In \eqref{eqn:approxdrift} we used the definition of the derivative of the one dimensional Kantorovich potential, which was defined in Section~\ref{sec:sw}. 

Given the fact that $\hat{\mu}^N_{kh}$ will be a collection of Dirac measures, i.e.\ $\hat{\mu}^N_{kh} = \frac1{N} \sum_{i=1}^N \delta_{\bar{X}_{k}^i}$, we directly have $\theta_{n\#\hat{\mu}^N_{kh}}^* = \frac1{N} \sum_{i=1}^N \delta_{\langle \theta_n, \bar{X}_{k}^i \rangle} $, that is the one-dimensional empirical distribution of the projected samples $\{\langle \theta_n, \bar{X}_{k}^i \rangle\}_{i=1}^N$. Similarly, for a given dataset ${\cal D} \equiv \{y_i\}_{i=1}^P$, we have $\theta_{n\#\nu}^* = \frac1{N} \sum_{i=1}^P \delta_{\langle \theta_n, y_i \rangle} $, that is the one-dimensional empirical distribution of the projected data points $\{\langle \theta_n, y^i \rangle\}_{i=1}^P$. Once the projections of the particles and the data points are computed along the directions $\{\theta_n\}_n$, it is straightforward to approximately compute the function $(F_{\theta_{n\#\hat{\mu}}^*}^{-1} \circ F_{\theta_{n\#\nu}}) $ by using standard linear interpolation techniques \umut{cite}, whose details are given in the supplementary document. Since each of these computations are one-dimensional, the error induced at this step is negligible. 











