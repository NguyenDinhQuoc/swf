%!TEX root = ./nips_2018_sketchmcmc.tex

\section{Regularized Sliced-Wasserstein Flows for Generative Modeling}

% \begin{itemize}
% \item Start from the flow given in \cite{bonnotte2013unidimensional} and discuss the limitations 
% \begin{itemize}
% \item No convergence guarantee
% \item Over-fitting risk when the target is a collections of Dirac masses
% \end{itemize}
% \item Motivation for the entropy-regularization (discuss the differences with the Sinkhorn distances \cite{genevay2018learning})
% \item Development of the new gradient flow -- first theoretical result
% \item Establish the distance between the stationary measures of the two gradient flows (second theoretical result)
% \item View the new flow as a non-linear Fokker-Planck equation -- establish the connection with the appropriate SDE
% \item Develop the numerical scheme 
% \item Analyze the TV distance between the measure at iteration $k$ and the invariant measure
% \item We don't need to see the data, we just need the projections. In addition to its computational implications, this can be crucial for privacy preserving applications
% \end{itemize}


Bonnotte \cite{bonnotte2013unidimensional} considers the IDT algorithm \cite{pitie2005n} and develops a continuity equation, given as follows:
\begin{align}
\partial_t \rho_t - \nabla \cdot (\rho_t v_t) = 0,
\end{align}
where $\rho_t$ is the density of $\mu_t$ and
\begin{align}
v_t(x) \triangleq \int_{\mathbb{S}^{d-1}} \psi'_{t,\theta}(\langle \theta, x \rangle) \theta \> d\theta. \label{eqn:idt_v}
\end{align}
Here, $\psi_{t,\theta}$ denotes the Kantorovich potential between $\theta^*_{\#}\mu_t$ and $\theta^*_{\#}\nu$. In fact, one can show that, this is nothing but a gradient flow in the Wasserstein spaces, given as follows:
\begin{align}
\partial_t \rho = - \nabla_{\W} \F(\rho) \label{eqn:gradflow}
\end{align}
where $\nabla_{\W}$ denotes a notion of gradient in the $\W$ metric and the functional $\F$ is chosen as the squared sliced-Wasserstein distance between $\mu$ and $\nu$:
\begin{align}
\F(\rho) \triangleq \frac1{2} \SW^2(\rho, \pi)
\end{align}
where $\pi$ denotes the density of $\nu$. Here we abused the notation by defining $\SW$ on the densities instead of the measures; we implicitly assume that both measures $\mu$ and $\nu$ are dominated by the Lebesgue measure. This gradient flow basically constructs a path $(\rho_t)_{t\geq 0}$ that minimizes $\F$ as $t$ increases. In other words, the goal in construction such a flow is to solve the following problem:
\begin{align}
\rho^\star = \argmin_\rho \F(\rho).
\end{align}
Since we obviously have $\rho^\star = \pi$, this gradient flow will start from $\rho_0$ and bring it closer to $\pi$ as $t$ evolves.

% By following \cite{santambrogio2017euclidean}, the gradient given in \eqref{eqn:gradflow} can be written as follows:
% \begin{align}
% \nabla_{\W} \F(\rho) = -\nabla \cdot \Bigl( \rho \nabla \bigl( \frac{\delta \F}{\delta \rho}(\rho) \bigr) \Bigr), \label{eqn:gradw2}
% \end{align}
% where $\frac{\delta \F}{\delta \rho}(\rho)$ denotes the first variation of $\F$.

By this definition, $\mu_t$ should directly go to $\nu$. However, in practical settings, we will have finitely many samples from $\mu_0$ and $\nu$, therefore this scheme will somehow `overfit' to the data distribution. Therefore what we propose is to somehow `regularize' the gradient flow by introducing an entropy term to the minimization process. In particular, we modify the gradient flow given in \eqref{eqn:gradflow} as follows:
\begin{align}
\partial_t \rho = - \nabla_{\W} \F_\lambda(\rho),
\end{align}
where
\begin{align}
\F_\lambda(\rho) \triangleq \F(\rho) + \lambda \He(\rho).
\end{align}
Here, $\He(\rho) \triangleq \int (h \circ \rho) (x) dx $ denotes the negative entropy of $\rho$ with $h(t) = t \log t$. This regularization somewhat corresponds to assuming a Gaussian prior on the density $\rho$: when $\lambda$ goes to infinity, the optimal $\rho$ that minimizes $\F_\lambda$ will be a Gaussian density since the Gaussian densities have the maximum entropy.

This time the optimization problem is modified:
\begin{align}
\min_\rho \F_\lambda(\rho),
\end{align}
in which $\pi$ is no longer an optimizer. The idea in this new gradient flow formulation is to take $\rho_t$ as close as possible to $\pi$, while trying to keep its entropy at a certain level, so that it would be expressive for generative modeling purposes.

We can now construct the modified gradient flow as follows:
\begin{align}
\partial_t \rho &= - \nabla_{\W} \F_\lambda(\rho) \\
&=  \nabla \cdot (\rho \> v_t) + \lambda \Delta \rho. \label{eqn:gradflow_reg}
\end{align}

Here, we present our first theoretical result. 
\begin{thm}
The gradient flow is a valid gradient flow. \umut{Szymon.}
\end{thm}


\subsection{Connection with stochastic differential equations}

We now consider the modified flow given in \eqref{eqn:gradflow_reg}. We can observe that, this equation is a Fokker-Planck-type equation that has a probabilistic counterpart. More precisely, the following stochastic differential equation (SDE):
\begin{align}
d X_t = - v_t(X_t) dt + \sqrt{2 \lambda } d W_t, \label{eqn:sde}
\end{align}
where $W_t$ denotes the standard Brownian motion, is associated with \eqref{eqn:gradflow_reg}, in the sense that the probability measures of the solution process $(X_t)_{t\geq0}$ satisfies the flow \eqref{eqn:gradflow_reg}.  

\begin{assumption}
\label{asmp:sde_ergo}
For all $\lambda >0$, the SDE  \eqref{eqn:sde} has a unique strong solution denoted by $(X_t)_{t\geq 0}$ for any starting point $x \in \R^d$. It defines a non-homogenous Markov semi-group $(P_{s,t})_{t\geq s\geq 0}$ which admits a unique invariant measure denoted by $\nu_\lambda$. 
\end{assumption}



We first provide a bound between the invariant measure $\nu_\lambda$ and $\nu$.

\begin{prop}
\label{prop:dist_statmeas}
Assume that the SDE \eqref{eqn:sde} satisfies \Cref{asmp:sde_ergo}. Denote the probability distribution of $X_t$ at time $t$ by $\mu_t(dx) = \rho_t (x) dx$. Furthermore, consider the following SDE
\begin{align}
d Y_t = - v_t(Y_t) dt + \sqrt{2 \epsilon } d W_t. \label{eqn:sde_eps}
\end{align}
Assume that it satisfies \Cref{asmp:sde_ergo} and denote the probability of $Y_t$ at time $t$ by $\mu^\epsilon_t$ which admits a density $\rho^\epsilon_t$. Further assume that for all $\epsilon,t>0$, there exists $C >0$ that depends on $t$, such that
\begin{align}
\int_{0}^t \int_{\R^d} \frac{\|\nabla \rho^\epsilon_s(x) \|^2}{\rho^\epsilon_s(x)} dx ds <C, \qquad \text{and} \qquad \int_{0}^t \int_{\R^d}  \frac{\|\nabla \rho^\epsilon_s(x)\|}{1+\|x\|} dx ds <\infty.
\end{align}
Then the following bound holds:
\begin{align}
\lim_{\epsilon \rightarrow 0} \| \mu_t - \mu^\epsilon_t \|_{\TV}^2 \leq 2 C \lambda,
\end{align}
where $\|\mu-\nu\|_{\TV}$ denotes the total variation distance between two probability measures $\mu$ and $\nu$, defined as follows: $\|\mu-\nu\|_{\TV}\triangleq \sup_{A \in {\cal B}(\Omega)} |\mu(A) -\nu(A) |$.
\end{prop}

\section{Discretized Particle System for Simulating the SDE}

Proposition~\ref{prop:dist_statmeas} shows that if we could simulate \eqref{eqn:sde}, then we could use the sample paths $(X_t)_t$ as
samples drawn from $\nu_\lambda$, which is not very far from $\nu$. However, in practice this is not possible due to two reasons: (i) the drift $v_t$ cannot be computed analytically since it depends on the measure at time $t$, i.e.\ $\mu_t$, (ii) the SDE \eqref{eqn:sde} is a continuous-time process, it needs to be discretized.  

We now focus on the first issue. In order to highlight the fact that the drift in \eqref{eqn:sde} depends on $\mu_t$, within this section we will denote the drift as $v_t(x) \equiv v(x, \mu_t)$. With this notation, it can be clearly observed that the SDE \eqref{eqn:sde} is similar to McKean-Vlasov SDEs \cite{veretennikov2006ergodic,mishura2016existence} whose drift depends on the distribution of $X_t$ as well. By using this connection, we borrow tools from the relevant SDE literature \cite{malrieu03,cgm-08} for developing and approximate simulation method for \eqref{eqn:sde}. 

Our approach is based on defining a \emph{particle system} that serves as an approximation to the original SDE \eqref{eqn:sde}, and is given as follows:
\begin{align}
d X_t^i = - v(X_t^i, \mu_t^{(N)}) dt + \sqrt{2 \lambda } d W_t^i \> , \quad i = 1,\dots, N, \label{eqn:sde_particle}
\end{align}
where $i$ denotes the particle index, $N \in \mathbb{N}_+$ denotes the total number of particles, and $\mu_t^{(N)}$ denotes the law of the particles $\{X_t^j\}_{j=1}^N$. This particle system is particularly interesting, since (i) one typically has $\lim_{N \rightarrow \infty} \mu_t^{(N)}= \mu_t $ and the distance between $\mu_t^{(N)}$ and $\mu_t$ is of order ${\cal O}(1/\sqrt{N})$ for $t$ large enough \cite{malrieu03,cgm-08}, and (ii) each of the particle systems in \eqref{eqn:sde_particle} can be efficiently simulated by using an Euler-Maruyama discretization scheme. We note that the existing theoretical results in \cite{veretennikov2006ergodic,mishura2016existence} do not directly apply to our case due to the non-standard form of our drift. However, we conjecture that a similar result holds for our problem as well. Proving such a result is technically very involved and we leave it out of the scope of this study. %We will support this claim with experimental results.

We now consider the approximate Euler-Maruyama discretization for each particle, that is given as follows:
\begin{align}
\bar{X}^i_{k+1} = \bar{X}^i_k - h \hspace{0.5pt} \hat{v}(\bar{X}^i_k, \hat{\mu}_{kh}^N ) + \sqrt{2 \lambda h} Z^i_{k+1},
\end{align}
where $k \in \mathbb{N}_+$ denotes the iteration number, for each particle $i$, $\{Z^i_k\}_{k}$ denotes a series of standard Gaussian random variables, $h$ denotes the step-size, and $\hat{v}$ is a computationally tractable estimator of $v$. Here, all the initial particles $\{\bar{X}_0^i\}_{i=1}^N$ are i.i.d.\ samples from $\mu_0$.

