%!TEX root = ./icml_2019_sketchmcmc.tex

\section{Technical Background}
\label{sec:techbg}



% \subsection{Wasserstein distance, optimal transport maps and Kantorovich potentials}

\vspace{-5pt}

\subsection{Wasserstein distance, optimal transport maps and Kantorovich potentials }
% \textbf{Wasserstein distance, optimal transport maps and Kantorovich potentials: }
%
For two probability measures $\mu,\nu \in \PS_2(\Omega)$, $\PS_2(\Omega) = \{ \mu \in \PS(\Omega) \, :\, \int_{\Omega} \norm[2]{x} \mu(\rmd x) < \plusinfty\}$, the 2-Wasserstein distance is defined as follows:
\begin{align}
\W(\mu,\nu) \triangleq \Bigl\{ \inf_{\gamma \in {\cal C}(\mu,\nu)} \int_{\Omega \times \Omega} \|x-y\|^2 \gamma(dx , dy) \Bigr\}^{1/2}, \label{eqn:w2}
\end{align}
where ${\cal C}(\mu,\nu)$ is called the set of \emph{transportation plans} and defined as the set of probability measures $\gamma$ on $\Omega \times \Omega$ satisfying for all $A \in {\cal A}$, $\gamma(A \times \Omega) = \mu(A)$ and $\gamma(\Omega \times A)=\nu(A)$, i.e. the  marginals of $\gamma$  coincide with $\mu$ and $\nu$. From now on, we will assume that $\Omega$ is a compact subset of $\R^d$.


In the case where $\Omega$ is finite, computing the Wasserstein distance between two probability measures turns out to be  a linear program with linear constraints, and has therefore a dual formulation. Since $\Omega$ is a Polish space (i.e.\ a complete and separable metric space), this dual formulation can be generalized as follows \cite{villani2008optimal}[Theorem 5.10]:
\begin{align}
\W(\mu,\nu) \hspace{-1pt} = \hspace{-6pt} \sup_{\psi \in \mathrm{L}^1(\mu)} \Bigl\{ \int_\Omega \psi(x) \mu(dx) + \int_\Omega \psi^c(x) \nu(dx) \Bigr\}^{1/2} \label{eqn:w2dual}
\end{align}
where $\mathrm{L}^1(\mu)$ denotes the class of functions that are absolutely integrable under $\mu$ and $\psi^c$ denotes the c-conjugate of $\psi$ and is defined as follows: $\psi^c(y) \triangleq \{ \inf_{x\in \Omega} \| x-y\|^2 - \psi(x)\}$. The functions $\psi$ that realize the supremum in \eqref{eqn:w2dual} are called the Kantorovich potentials between $\mu$ and $\nu$.
%
Provided that $\mu$ satisfies a mild condition, we have the following  uniqueness result.
\begin{thm}[\protect{\cite{santambrogio2010introduction}[Theorem 1.4]}]
\label{thm:unqmap}
Assume that  $\mu\in \PS_2(\Omega)$ is absolutely continuous with respect to the Lebesgue measure. Then, there exists a unique optimal transport plan $\gamma^\star$ that realizes the infimum in \eqref{eqn:w2} and it is of the form $(\text{Id} \times T)_\# \mu$, for a measurable function $T : \Omega \to \Omega$. Furthermore, there exists at least a Kantorovich potential $\psi$ whose gradient $\nabla \psi$ is uniquely determined $\mu$-almost everywhere. The function $T$ and the potential $\psi$ are linked by $T(x) = x- \nabla \psi(x)$.
\end{thm}
The measurable function $T : \Omega \to \Omega$ is referred to as the optimal transport map from $\mu$ to $\nu$.
This result implies that there exists a solution for transporting samples from $\mu$ to samples from $\nu$ and this solution is optimal in the sense that it minimizes the $\ell_2$ displacement. However, identifying this solution is highly non-trivial. In the discrete case, effective solutions have been proposed \cite{cuturi2013sinkhorn}. However, for continuous and high-dimensional probability measures, constructing an actual transport plan remains a challenge. Even if recent contributions \cite{genevay2016stochastic} have made it possible to rapidly compute $\W$, they do so without constructing the optimal map $T$, which is our objective here.


\subsection{Wasserstein spaces and gradient flows}

% \textbf{Wasserstein spaces and gradient flows: }
%
By \cite{ambrosio2008gradient}[Proposition 7.1.5], $\W$ is a distance over $\PS(\Omega)$.
In addition, if $\Omega \subset \R^d$ is compact, the topology associated with $\W$ is equivalent to the weak convergence of probability measures and $(\PS(\Omega),\W)$\footnote{Note that in that case, $\PS_2(\Omega)=\PS(\Omega)$} is compact. The metric space $(\PS_2(\Omega),\W) $ is called the \emph{Wasserstein space}.

In this study, we are interested in functional optimization problems in $(\PS_2(\Omega),\W)$, such as $\min_{\mu\in\PS_2(\Omega)} \F(\mu)$, where $\F$ is the functional that we would like to minimize. Similar to Euclidean spaces, one way to formulate this optimization problem is to construct a gradient flow of the form $\partial_t \mu_t = - \nabla_{\W} \F(\mu_t)$, where $\nabla_{\W}$ denotes a notion of gradient in $(\PS_2(\Omega),\W)$. If such a flow can be constructed, then one can utilize it both for practical algorithms and theoretical analysis.

Gradient flows $\partial_t \mu_t = \nabla_{\W} \mathcal{F}(\mu_t)$ with respect to a functional $\mathcal{F}$ in $(\PS_2(\Omega),\W)$ have strong connections with partial differential equations (PDE) that are of the form of a \emph{continuity equation} \cite{santambrogio2017euclidean}. Indeed, it is shown than under appropriate conditions on $\mathcal{F}$ (see \eg \cite{ambrosio2008gradient}), $(\mu_t)_t$ is a solution of the gradient flow if and only if it admits a density $\rho_t$ with respect to the Lebesgue measure for all $t \geq 0$, and solves the continuity equation given by:
% \begin{align}
$\partial_t \rho_t + \divop (v \rho_t) = 0$, %  \label{eqn:pde}
% \end{align}
where $v$ denotes a vector field and $\divop$ denotes the divergence operator. Then, for a given gradient flow in $(\PS_2(\Omega),\W)$, we are interested in the evolution of the densities $\rho_t$, i.e.\ the PDEs which they solve.
%
Such PDEs are of our particular interest since they have a key role for building practical algorithms.




\subsection{Sliced-Wasserstein distance}
% \label{sec:sw}

% \textbf{Sliced-Wasserstein distance: }
%
In the one-dimensional case, i.e.\ $\mu,\nu \in \PS_2(\R)$, $\W$ has an analytical form, given as follows:
% \begin{align}
$\W(\mu,\nu) = \int_0^1 |F_\mu^{-1}(\tau) - F_\nu^{-1}(\tau)|^2 \> d\tau$, %\label{eq:W1D}
% \end{align}
where $F_\mu$ and $F_\nu$ denote the cumulative distribution functions (CDF) of $\mu$ and $\nu$, respectively, and $F^{-1}_\mu, F^{-1}_\nu$ denote the inverse CDFs, also called quantile functions (QF).
%
In this case, the optimal transport map from $\mu$ to $\nu$  has a closed-form formula as well, given as follows: $T(x) = (F_\nu^{-1} \circ F_\mu) (x)$ \cite{villani2008optimal}. The optimal map $T$ is also known as the \emph{increasing arrangement}, which maps each quantile of $\mu$ to the same quantile of $\nu$, e.g. minimum to minimum, median to median, maximum to maximum \cite{villani2008optimal}.
%
Due to Theorem~\ref{thm:unqmap}, the derivative of the corresponding Kantorovich potential is given as:
\begin{align*}
\psi'(x) \triangleq \partial_x \psi(x) = x- (F_\nu^{-1} \circ F_\mu) (x).
\end{align*}

In the multidimensional case $d > 1$, building a transport map is much more difficult. The nice properties of the one-dimensional Wasserstein distance motivate the usage of \emph{sliced-Wasserstein distance} ($\SW$) for practical applications. Before formally defining $\SW$, let us first define the orthogonal projection $\theta^* (x) \triangleq \langle \theta, x \rangle$ for any direction $\theta \in \Sp^{d-1}$ and $x \in \R^d$, where $\langle \cdot, \cdot \rangle$ denotes the Euclidean inner-product and $\Sp^{d-1} \subset \R^d$ denotes the $d$-dimensional unit sphere. Then, the $\SW$ distance is formally defined as follows:
\begin{align}
\SW(\mu,\nu) \triangleq \int_{\Sp^{d-1}} \W (\theta^*_\#\mu, \theta^*_\#\nu) \> d \theta, \label{eqn:sw}
\end{align}
where $d\theta$ represents the uniform probability measure on $\Sp^{d-1}$. As shown in \cite{bonnotte2013unidimensional}, $\SW$ is indeed a distance metric and induces the same topology as $\W$ for compact domains.

The $\SW$ distance has important practical implications: provided that the projected distributions $\theta^*_\#\mu$ and $\theta^*_\#\nu$ can be computed, then for any $\theta \in \Sp^{d-1}$, the distance $\W (\theta^*_\#\mu, \theta^*_\#\nu)$, as well as its optimal transport map and the corresponding Kantorovich potential can be analytically computed (since the projected measures are one-dimensional). Therefore, one can easily approximate \eqref{eqn:sw} by using a simple Monte Carlo scheme that draws uniform random samples from $\Sp^{d-1}$ and replaces the integral in \eqref{eqn:sw} with a finite-sample average. Thanks to its computational benefits, $\SW$ was very recently considered for OT-based VAEs and GANs \cite{deshpande2018generative,autotranspoter,kolouri2018sliced}, appearing as a stable alternative to the adversarial methods.





%%% Local Variables:
%%% mode: latex
%%% TeX-master: "aistats_2019_sketchmcmc"
%%% End:
